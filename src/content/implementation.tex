%----------------------------------------------------------------------------
\chapter{Implementation}
%----------------------------------------------------------------------------
\section{Different versions of NI LabVIEW}
At the time of writing this thesis, National Instruments offers two versions of LabVIEW: LabVIEW 2018\footnote{\url{http://www.ni.com/en-us/shop/labview/labview-details.html}}, and LabVIEW NXG\footnote{\url{http://www.ni.com/en-us/shop/labview/labview-nxg.html}}. LabVIEW 2018 is a sequel to the LabVIEW versions released in the past few years, it operates reliably and fast, has support for all the NI hardware, and has a wide range of features. LabVIEW NXG is a brand new product, it has been created from scratch, and has been developed according to current standards - optimized for the newest hardware and software, and a really comfortable UI. Most features are still beta however, or under development\footnote{\url{http://www.ni.com/pdf/products/us/labview-roadmap.pdf}}, a large number of hardware are not yet supported, and the operation is not as reliable as the current generation software.\cite{nxg_article}

LabVIEW 2018 and LabVIEW NXG are not really compatible with each other, though the interface and the programming is similar, they have completely different execution engines and file formats. There is a tool bundled with NXG for current generation project conversion, but it is not perfect, and almost always the converted VIs need manual fixing afterwards.

Given two distinct LabVIEW products, it has to be decided which to develop the tool for. Both of them have advantages: current generation LabVIEW has a larger user base than NXG, but developing for NXG will make the tool compatible with actual software for a longer time (since NXG will eventually replace current generation LabVIEW).
\subsection{Comparing the API}
For making a decision on the LabVIEW version, the main point was the method of integrating the tool into LabVIEW. 

Reading the VI data from file is quite difficult. The file format definition of current generation VIs is not published, so the only software that can read the file is LabVIEW. NXG stores the VI data in XML files, which is a lot friendlier. It is possible to create an interpreter, and build the object model, since the nodes are XML elements, and the connections are made using unique identifiers.

Building a plugin is an option too. LabVIEW 2018 has a toolbox called VI Scripting\footnote{\url{http://sine.ni.com/nips/cds/view/p/lang/en/nid/209110}} for G language. It has several commands to access or modify VI object models and project structure. Project Provider Framework\footnote{\url{http://www.ni.com/white-paper/13921/en/}} allows an add-on to be integrated into the interface of LabVIEW, like creating a menu command or a toolbar button.

A plugin for LabVIEW NXG needs a different approach. Most of NXG uses .NET framework, and an add-on integrates in a form of a .NET class library (DLL). The object model of a Virtual Instrument is directly accessible as a .NET object, and plugin entry points can easily be defined with class attributes. UI elements can be easily created as well. This way, the plugin is written in C\# language.

I have chosen to create an NXG plugin, since writing such a complex tool in G language would require such an expertise in LabVIEW, that I do not have. Additionally, I already had the routine in NXG API and C\#.
\section{LabVIEW NXG API and object model}
There is hardly any documentation on the NXG programming interface at the moment, but an example plugin project on GitHub\footnote{\url{https://github.com/ni/nidevlabs}}. Fortunately, this project had almost all the API I needed for this project.
\lstset{escapechar=@}
\begin{lstlisting}[frame=single,escapechar=@,float=!ht,caption={NXG plugin entry point},captionpos=b,label={lst:menuapi},language=C++]
[ExportPushCommandContent]
public class LauncherCommands : PushCommandContent
{
    public static readonly ICommandEx SymbolicMenuRoot = new RelayCommandEx(RelayCommandEx.HandleNoOp)
    {
        UniqueId = "SymbolicTool.MenuRoot",
        LabelTitle = "SymbolicTool",
        MenuParent = MenuPathCommands.RootMenu
    };
    public readonly ICommandEx RunCommand = new ShellRelayCommand(OnRun)
    {
        UniqueId = "SymbolicTool.RunCommand",
        LabelTitle = "Run Symbolic Execution",
        MenuParent = SymbolicMenuRoot
    };
    public override void CreateApplicationContent(ICommandPresentationContext context)
    {
        base.CreateApplicationContent(context);
        context.Add(SymbolicMenuRoot);
        context.Add(RunCommand);
    }
    public static void OnRun(ICommandParameter parameter, ICompositionHost host, DocumentEditSite site)
    {
        // Run the program here
    }
}
\end{lstlisting}

\begin{figure}

\centering
\includegraphics[width=80mm,keepaspectratio]{figures/lvobject.pdf}
\caption{LabVIEW Node object model} 
\label{fig:lvobject}
\end{figure}
I implemented a launcher code based on the ExamplePlugins project, that integrates a menu command into the menu bar of NXG (Listing \ref{lst:menuapi}). The three parameters of the callback function provide access to the object model of LabVIEW. DocumentEditSite refers to the currently opened document, and since the execution will run on the opened VI, getting the model will be really easy: \lstinline[columns=fixed]{rootElement = site.ActiveDocumentEditor?.EditorInfo?.RootElement;}. The model will be passed to the parser component, then the returned Sequence object (which holds the procedural program) is given to the symbolic execution module (Listing \ref{lst:launchercode}). When finished, values of symbolic variables will be placed in each leaf, and can be retrieved using a \lstinline[columns=fixed]{leaf.getSymbols()} call.
\lstset{escapechar=@}
\begin{lstlisting}[frame=single,escapechar=@,float=!ht,caption={Launcher code},captionpos=b,label={lst:launchercode},language=C++]
public static void OnRun(ICommandParameter parameter, ICompositionHost host, DocumentEditSite site)
{
    var rootElement = site.ActiveDocumentEditor?.EditorInfo?.RootElement;
    if (rootElement == null) return;
    var sequence = VIConverter.VIConverter.CreateModel(rootElement);
    Symbolic.SymbolicExec se = new Symbolic.SymbolicExec(sequence.getStatements());
    List<Symbolic.ExecutionState> leafs = se.Execute();
    // Print symbolic variable values
}
\end{lstlisting}
\section{The parser}
The algorithm used in the main parser loop is a sort of breadth-first search. The nodes waiting to be processed get placed in a queue object (which initializes with those nodes, that have no input wires, and can be executed right away). The main loop takes a node from the front of the queue, and makes sure all its input nodes are already processed - this is important, because at the end of processing a node, all the output nodes are added to the queue, and they not necessarily have all their inputs ready. 

A \textit{Statement}\footnote{Note: the classes of my implementation are indicated with \textit{italic}, the classes of LabVIEW API are indicated with \underline{underlined} font} is created for the node, then the arithmetical, logical or other \textit{Operation}s are added respectively. When the node is a \underline{DataAccessor} (LabVIEW control), a \textit{SymbolicVariable} will be introduced.

The parser binds a \textit{Variable} to all of the wires. New \textit{Variable}s are introduced, when the parser processes the output wires of a node (since a wire can be connected to only one node output), and all \underline{ManhattanWire} - \textit{Variable} pairs will be stored in a lookup table (C\# Dictionary) global to a single run of the algorithm. This way, if multiple nodes use that output as an input, it will be the same \textit{Variable}.

When the search reaches a case structure, the parser will be recursively called for both subdiagrams. Wires enter the case diagram through \underline{BorderNode}s (or tunnels), so that for each of them a new \textit{Variable} will be introduced. In a subdiagram, the search will start from the \underline{BorderNode}s (and the nodes without input wires). After the search execution for both diagrams, the execution returns to the root parser.

To summarize, the simplified pseudo-code is listed below (Algorithm \ref{alg:parser}), that is easier to understand. 
The explanation of data structures used during the operation of the parser:

\begin{itemize}
\item \textbf{rootElement} : \underline{Element} -- the parameter of the algorithm, the diagram, whose immediate child nodes must be searched
\item \textbf{nextNodes} : Queue<\underline{Wireable}> -- found \underline{Nodes}, waiting to be processed
\item \textbf{variableDictionary} : Dictionary<\underline{ManhattanWire}, \textit{Variable}> -- association between LabVIEW wires and variables in the procedural program
\item \textbf{sequence} : \textit{Sequence} -- the procedural program, chain of \textit{Statement}s, the result of this algorithm
\end{itemize}


\SetKwProg{Fn}{}{}{}
\begin{algorithm}
\ForEach{nodes of rootElement without input wires}{
add node to nextNodes\;
}
\If{rootElement is NestedDiagram}{
\ForEach{input tunnels}{
add output nodes to nextNodes\;
}
}
\While{nextNodes is not empty}{
thisNode:=nextNodes.Dequeue\;
\eIf{thisNode has all inputs ready}{
statement:=new Statement\;
inputVariables:=variableDictionary[input wires of thisNode]\;
\ForEach{output wires of thisNode}{
variableDictionary[output wire]:=new Variable\;
}
\Switch{type of thisNode}{
\uCase{SourceModel.Add}{statement.addOperation(createAssignment(outputVariables[0], createAddition(inputVariables[0], inputVariables[1])))\;}
\uCase{SourceModel.Multiply}{statement.addOperation(createAssignment(outputVariables[0], createMultiplication(inputVariables[0], inputVariables[1])))\;}
\vspace{2mm}
...\\
\uCase{SourceModel.Literal}{statement.addOperation(createAssignment(outputVariables[0], createConstant(thisNode.Data)))\;}
\uCase{SourceModel.DataAccessor}{statement.addOperation(createAssignment(outputVariables[0], createSymbolicVariable(thisNode.DataItemName)))\;}
\Case{SourceModel.BorderNode}{
\If{thisNode.Owner is CaseStructure and all its inputs are ready}{
create variables for all input and output tunnels\;
statement:=new IfStatement\;
statement.trueBranch:=Parser(true diagram)\;
statement.falseBranch:=Parser(false diagram)\;

}
}
}
sequence.add(statement)\;
\ForEach{follow output wires of thisNode}{
nextNodes.Enqueue(found node)\;
}
}{
nextNodes.Enqueue(thisNode)\;
}

}
 \caption{A simplified algorithm of Parser(rootElement)}
 \label{alg:parser}
\end{algorithm}

Of course, this is more of a demonstration, than the actual program. A number of workaround solutions had to be used to handle special cases, for example when a case structure had two output tunnels, that connect to one source in the subdiagram, two variables were created for the same wire, which is invalid. The second variable had to be assigned the value of the first variable.

Since references from one LabVIEW object to another were mostly using a heterogenous collection, type checks and type casts take up a large percentage of the source code.